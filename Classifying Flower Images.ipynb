{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project is from one of my assignments for STAT5242 Advanced Machine Learning. The task is to use a small collection of photos (500 to be exact) to construct a flower-image classifier capable of discerning differences between daisies, roses, dandelions, sunflowers, and tulips. <br>\n",
    "My approach was to leverage what a pre-trained convolutional neural network has already learned about important image features from the imagenet dataset. Then I removed the last layer, fixed the weights of the remaining layers, used what remains as a black-box function transforming images into derived feature vectors, and finally fitted a new classifier on the derived feature vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/youyang/anaconda/lib/python3.6/importlib/_bootstrap.py:205: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import os.path\n",
    "import transfer_learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "INCEPTION_LOG_DIR = '/Users/youyang/tmp/inception_v3_log'\n",
    "if not os.path.exists(INCEPTION_LOG_DIR):\n",
    "    os.makedirs(INCEPTION_LOG_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Looking for images in 'daisy'\n",
      "WARNING:tensorflow:WARNING: Folder daisy has more than 100 images. Some images will never be selected.\n",
      "INFO:tensorflow:Looking for images in 'dandelion'\n",
      "WARNING:tensorflow:WARNING: Folder dandelion has more than 100 images. Some images will never be selected.\n",
      "INFO:tensorflow:Looking for images in 'roses'\n",
      "WARNING:tensorflow:WARNING: Folder roses has more than 100 images. Some images will never be selected.\n",
      "INFO:tensorflow:Looking for images in 'sunflowers'\n",
      "WARNING:tensorflow:WARNING: Folder sunflowers has more than 100 images. Some images will never be selected.\n",
      "INFO:tensorflow:Looking for images in 'tulips'\n",
      "WARNING:tensorflow:WARNING: Folder tulips has more than 100 images. Some images will never be selected.\n"
     ]
    }
   ],
   "source": [
    "training_images, testing_images, label_maps = transfer_learning.create_image_lists('./data/flower_photos',testing_percentage=10, max_number_images=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph, bottleneck, resized_input, softmax = transfer_learning.create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    jpeg_data, decoded_image = transfer_learning.make_jpeg_decoding()\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        summary_writer = tf.summary.FileWriter('/Users/youyang/tmp/inception_v3_log', graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_bottleneck(session, image_data):\n",
    "    \n",
    "   \n",
    "    jpeg_data_tensor = session.run(decoded_image, feed_dict={jpeg_data: image_data})\n",
    "    bottleneck_tensor = session.run(bottleneck, feed_dict = {resized_input: jpeg_data_tensor})   \n",
    "\n",
    "    return bottleneck_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1/456 bottlenecks\n",
      "Saved 21/456 bottlenecks\n",
      "Saved 41/456 bottlenecks\n",
      "Saved 61/456 bottlenecks\n",
      "Saved 81/456 bottlenecks\n",
      "Saved 101/456 bottlenecks\n",
      "Saved 121/456 bottlenecks\n",
      "Saved 141/456 bottlenecks\n",
      "Saved 161/456 bottlenecks\n",
      "Saved 181/456 bottlenecks\n",
      "Saved 201/456 bottlenecks\n",
      "Saved 221/456 bottlenecks\n",
      "Saved 241/456 bottlenecks\n",
      "Saved 261/456 bottlenecks\n",
      "Saved 281/456 bottlenecks\n",
      "Saved 301/456 bottlenecks\n",
      "Saved 321/456 bottlenecks\n",
      "Saved 341/456 bottlenecks\n",
      "Saved 361/456 bottlenecks\n",
      "Saved 381/456 bottlenecks\n",
      "Saved 401/456 bottlenecks\n",
      "Saved 421/456 bottlenecks\n",
      "Saved 441/456 bottlenecks\n",
      "Done computing bottlenecks!\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    with tf.Session() as session:\n",
    "        transfer_learning.cache_bottlenecks(compute_bottleneck, session, training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_data_set = transfer_learning.create_training_dataset(training_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_final_layers(bottleneck_tensor, num_classes):\n",
    "    bottleneck_tensor_size = int(bottleneck.shape[1])\n",
    "    \n",
    "    with tf.variable_scope('input'):\n",
    "        # This is the input for the bottleneck. \n",
    "        bottleneck_input = tf.placeholder_with_default(\n",
    "            bottleneck_tensor,\n",
    "            [None, bottleneck_tensor_size],\n",
    "            'bottleneck_input')\n",
    "        \n",
    "        # This is the input for the label (integer, 1 to number of classes)\n",
    "        label_input = tf.placeholder(tf.int64, [None], name='label_input')\n",
    "        \n",
    "    # Define weights, biases, and logit transforms\n",
    "    logits = tf.layers.dense(bottleneck_input, num_classes)\n",
    "    # Compute the cross entropy loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=label_input, logits=logits)\n",
    "    # Create a summary for the loss\n",
    "    loss_summary = tf.summary.scalar('cross_entropy', loss)\n",
    "    # Create a Gradient Descent Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.1)\n",
    "    # Obtain a function which performs a single training step\n",
    "    train_step = optimizer.minimize(loss)\n",
    "    \n",
    "    return bottleneck_input, label_input, logits, train_step, loss_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_accuracy(labels, logits):\n",
    "    \"\"\"Compute the accuracy for the predicted output.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    labels: The input labels (in a one-hot encoded fashion).\n",
    "    predicted_output: The predicted class probability for each output.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    A tensor representing the accuracy.\n",
    "    \"\"\"\n",
    "    with tf.name_scope('accuracy'):\n",
    "        \n",
    "        predicted_output = tf.argmax(logits, 1, name = 'pred_class')\n",
    "    \n",
    "        label_onehot = tf.one_hot(labels, depth = 5)\n",
    "        true_label = tf.argmax(label_onehot, 1, name = 'true_class')\n",
    "        accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted_output, true_label), tf.float32))\n",
    "    \n",
    "    accuracy_summary = tf.summary.scalar('accuracy_summary', accuracy)\n",
    "    \n",
    "    return accuracy, accuracy_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    bottleneck_input, label_input, logits, train_step, loss_summary = make_final_layers(bottleneck, len(label_maps))\n",
    "    accuracy, accuracy_summary = compute_accuracy(label_input, logits)\n",
    "    summary_op = tf.summary.merge([loss_summary, accuracy_summary])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_train_step(session: tf.Session, summary_writer: tf.summary.FileWriter, current_step: int):\n",
    "    \"\"\"This function runs a single training step.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    session: the tensorflow session to use to run the training step.\n",
    "    summary_writer: the summary file writer to write your summaries to.\n",
    "    current_step: the current step count (starting from zero)\n",
    "    \"\"\"\n",
    "    _, ac, summary = session.run((train_step, accuracy, summary_op),\n",
    "                       feed_dict={bottleneck_input: training_data_set['bottlenecks'],\n",
    "                                  label_input: training_data_set['labels']\n",
    "                                 })\n",
    "    \n",
    "    summary_writer.add_summary(summary, current_step)\n",
    "    \n",
    "    if current_step % 10 == 0:\n",
    "        print('Accuracy at step {0} is {1}'.format(current_step, ac))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_images(session: tf.Session, images_jpeg_data: [bytes], labels: [int]):\n",
    "    \"\"\"This function will evaluate the accuracy of our model on the specified data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    session: the tensorflow session to use to run the evaluation step.\n",
    "    images_jpeg_data: a list of strings, with each element in the list corresponding\n",
    "        to the jpeg-encoded data for a given image\n",
    "    labels: a list of integers, with each element in the list corresponding to the label\n",
    "        of a given image.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    This function should return the accuracy as a floating point number between\n",
    "    0 and 1 (proportion of correctly classified instances).\n",
    "    \"\"\"\n",
    "    correct = []\n",
    "    \n",
    "    for label, jpeg in zip(labels, images_jpeg_data):\n",
    "        image_data = session.run(decoded_image, feed_dict={jpeg_data: jpeg})\n",
    "        ac = session.run(accuracy, feed_dict={resized_input: image_data, label_input: [label]})\n",
    "        correct.append(ac)\n",
    "    \n",
    "    return np.mean(correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Starting training ----------------\n",
      "Accuracy at step 0 is 0.2017543911933899\n",
      "Accuracy at step 10 is 0.5197368264198303\n",
      "Accuracy at step 20 is 0.7039473652839661\n",
      "Accuracy at step 30 is 0.9320175647735596\n",
      "Accuracy at step 40 is 0.9451754093170166\n",
      "Accuracy at step 50 is 0.9583333134651184\n",
      "Accuracy at step 60 is 0.9758771657943726\n",
      "Accuracy at step 70 is 0.9758771657943726\n",
      "Accuracy at step 80 is 0.9824561476707458\n",
      "Accuracy at step 90 is 0.9868420958518982\n",
      "------------- Training done! -------------------\n",
      "---------- Loading testing data ----------------\n",
      "----------- Evaluating on testing --------------\n",
      "Evaluation accuracy was: 0.9090909361839294\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "    with tf.Session() as session:\n",
    "        print('------------- Starting training ----------------')\n",
    "        session.run(tf.global_variables_initializer())\n",
    "        summary_writer = tf.summary.FileWriter(os.path.join(INCEPTION_LOG_DIR, 'retrained'), graph)\n",
    "        for i in range(100):\n",
    "            execute_train_step(session, summary_writer, i)\n",
    "        summary_writer.close()  \n",
    "        print('------------- Training done! -------------------')\n",
    "        print('---------- Loading testing data ----------------')\n",
    "        tlabels, timages = transfer_learning.get_testing_data(testing_images)\n",
    "        print('----------- Evaluating on testing --------------')\n",
    "        \n",
    "        eval_accuracy = evaluate_images(session, timages, tlabels)\n",
    "        print('Evaluation accuracy was: {0}'.format(eval_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
